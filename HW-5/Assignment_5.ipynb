{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hochschule Bonn-Rhein-Sieg\n",
    "\n",
    "# Probabilistic Reasoning, WS21\n",
    "\n",
    "# Assignment 05\n",
    "\n",
    "Instructions for submission :\n",
    "- Please restart and run all cells before submitting \n",
    "- Make sure your user name is correct\n",
    "- No need to submit a pdf file, only the ipython is sufficient\n",
    "\n",
    "\n",
    "Instruction for assignment :\n",
    "\n",
    "- This is a two week long assignment,\n",
    "- The assignment uses the \"pgmpy\" library which can be used to represent and work with bayesian networks \n",
    "- Read the instruction in https://github.com/pgmpy/pgmpy to install the library\n",
    "- In the first week it is recommended to follow the working examples from https://github.com/pgmpy/pgmpy/tree/dev/examples to fammilarise yourself with the library \n",
    "- Second week can be used to finish the assignment \n",
    " \n",
    "\n",
    "Good luck !!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPython\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student user name: nmursa2s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Variable elimination [40 points]\n",
    "\n",
    "This exercise is rather simple to describe: you have to implement the variable elimination algorithm for answering queries in a Bayesian network. Now, implementing variable elimination from scratch is actually a lot of work, so most of it has therefore been done by us; however, you will have to fill in a few key functions that will make the skeleton code work correctly.\n",
    "\n",
    "In the cell below, we have two main classes, namely *Factor* and *ExactInferenceEngine*.\n",
    "\n",
    "1. *Factor* is a data structure for storing the factors used in variable elimination. The class exposes two methods: *multiply*, which takes the calling object as a first parameter and another factor as a second parameter, and *sum_out*, which takes the calling object as a first parameter and the name of a variable as a second parameter.\n",
    "2. *ExactInferenceEngine* is an interface for performing inference using variable elimination. The class exposes only one method, namely *perform_inference*, which takes the name of a query variable as a first parameter (we assume that we only have one query variable) and a dictionary of evidence variables and values as a second argument. The class has other methods as well, but they are all private, namely (i) *\\_\\_find_dependency_levels*, which sorts the terms of the joint distribution represented by a Bayesian network based on the variables that we have to sum out, (ii) *\\_\\_create_factors*, which creates the initial set of factors before we start performing inference, and (iii) *\\_\\_multiply_factors*, which takes a list of still active factors, a factor that acts as a placeholder of the current result of the inference process, a list of dependency levels as returned by *\\_\\_find_dependency_levels*, and the current level in the summation. The functionality of the private methods is fully implemented, so you don't have to implement anything there.\n",
    "\n",
    "**Your main task is to implement the methods *Factor.multiply*, *Factor.sum_out*, and part of the functionality of *ExactInferenceEngine.perform_inference***. In particular, *Factor.multiply* and *Factor.sum_out* are almost fully empty, so you have to implement the functionality pretty much completely; on the other hand, *ExactInferenceEngine.perform_inference* is almost fully written, but you have to implement the main inference loop (which amounts to you calling the appropriate methods with the appropriate parameters). The parts where you have to implement your code are clearly marked; please leave the rest of the code as it is. The code has quite a lot of comments, so you should in principle be able to understand how everything works and what you're expected to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factor(object):\n",
    "    def __init__(self, variables=[], values=[], probabilities=[]):\n",
    "        '''Defines a new factor of the variables in 'variables'.\n",
    "\n",
    "        Keyword arguments:\n",
    "        variables -- A list of variables in the factor.\n",
    "        values -- A 2D list of values of the factor variables.\n",
    "        probabilities -- A 2D list of probabilities\n",
    "                         corresponding to the factor variables;\n",
    "                         'probabilities' should be aligned with 'values', i.e.\n",
    "                         'probabilities[i]' should result from 'values[i]'.\n",
    "        '''\n",
    "        self.variables = variables\n",
    "        self.values = values\n",
    "        self.probabilities = probabilities\n",
    "\n",
    "    def multiply(self, other):\n",
    "        '''Multiplies 'self' with 'other'.\n",
    "\n",
    "        Keyword arguments:\n",
    "        other -- A 'Factor' object.\n",
    "\n",
    "        Returns:\n",
    "        new_factor -- A 'Factor' object representing the product of\n",
    "                      the factors 'self' and 'other'.\n",
    "        '''\n",
    "\n",
    "        #we create the set of variables in the new factor\n",
    "        new_variables = list(set(self.variables).union(set(other.variables)))\n",
    "        new_values = []\n",
    "        new_probabilities = []\n",
    "\n",
    "        ### Write your code here ###\n",
    "        ### as we know, VE works as performing two factor operations: product and marginalizaiton. \n",
    "        ### for our multiply method, we have to define the product of two factors\n",
    "        ### we can do it by multiplying these factors\n",
    "        ### the crucial thing here is that we have to multiply all factors containing X which is a variable\n",
    "        ### to be more precise, it exploits the product form of joint distribution\n",
    "\n",
    "        ### we saw the examples regarding to this, so in this function we have to write the joints as product\n",
    "        ### and we need to send the variables inside in order\n",
    "\n",
    "        for i, factor in enumerate(self.new_variables):\n",
    "            if other in factor[0]:\n",
    "                new_values.append(i)\n",
    "                new_probabilities.append(factor)\n",
    "        if len(new_values)>1:\n",
    "            for i in reversed(self.values):\n",
    "                del new_probabilities[i]\n",
    "        ### Your code ends here ###\n",
    "\n",
    "        new_factor = Factor(new_variables, new_values, new_probabilities)\n",
    "        return new_factor\n",
    "\n",
    "    def sum_out(self, variable):\n",
    "        '''Sums out 'variable' from the factor.\n",
    "\n",
    "        Keyword arguments:\n",
    "        variable -- Name of a variable in the factor.\n",
    "\n",
    "        Returns:\n",
    "        self\n",
    "        '''\n",
    "        variable_index = self.variables.index(variable)\n",
    "        new_values = []\n",
    "        new_probabilities = []\n",
    "\n",
    "        ### Write your code here ###\n",
    "        # in this case we have to have for loop for all the factors \n",
    "        # this function is used to sum out(basically removing) the variables \n",
    "        # as we sum over any variable, we get a function of other variables (we sum over that variable and keep other variables as function)\n",
    "        # we do it for some iterations, until getting to final sum \n",
    "\n",
    "        # to conclude, we have to eliminate the variables in their order, which will derive us the function of them \n",
    "        # so we can use this step over and over till last iteration to sum over all variables \n",
    "\n",
    "        for i, factor in enumerate(self.variables):\n",
    "            for j, v in enumerate(factor[0]):\n",
    "                if v == variable:\n",
    "                    new_probabilities = factor[0][:j]+factor[0][j+1]\n",
    "                for entry in factor[1]:\n",
    "                    entry = list(entry)\n",
    "                    new_key = tuple(entry[:j]+entry[j+1:])\n",
    "\n",
    "                    entry[j] = True\n",
    "                    prob1 = factor[1][tuple(entry)]\n",
    "                    entry[j]= False\n",
    "                    prob2 = factor[1][tuple(entry)]\n",
    "                    prob = prob1+prob2\n",
    "                    new_values[new_key] = prob\n",
    "        ### Your code ends here ###\n",
    "\n",
    "        self.variables.pop(variable_index)\n",
    "        self.values = new_values\n",
    "        self.probabilities = new_probabilities\n",
    "        return self\n",
    "\n",
    "\n",
    "class ExactInferenceEngine(object):\n",
    "    def __init__(self, network):\n",
    "        self.network = network\n",
    "\n",
    "    def perform_inference(self, query_variable, evidence_variables):\n",
    "        ''' Calculates the probability distribution \n",
    "        P(query_variable|evidence_variables) using variable elimination.\n",
    "        Assumes that we have only one query variable.\n",
    "\n",
    "        Keyword arguments:\n",
    "        query_variable -- The name of the query variable.\n",
    "        evidence_variables -- A dictionary containing variable names\n",
    "                              as keys and observed values as values.\n",
    "\n",
    "        Returns:\n",
    "        distribution -- A dictionary containing the values of the query\n",
    "                        variable as keys and the probabilities as values.\n",
    "        '''\n",
    "\n",
    "        known_variables = list(evidence_variables.keys())\n",
    "        known_variables.append(query_variable)\n",
    "        hidden_variables = []\n",
    "        for _,var in enumerate(self.network.nodes()):\n",
    "            if var not in known_variables:\n",
    "                hidden_variables.append(var)\n",
    "\n",
    "        variables, dependency_levels = \\\n",
    "        self.__find_dependency_levels(known_variables, hidden_variables)\n",
    "\n",
    "        #we don't want the query variable to be considered as known\n",
    "        #in the factor creation process\n",
    "        known_variables.remove(query_variable)\n",
    "        factors = self.__create_factors\\\n",
    "        (evidence_variables, variables, dependency_levels)\n",
    "\n",
    "        current_factor = Factor()\n",
    "        for i in range(len(hidden_variables)-1, -1, -1):\n",
    "            ### write your code here ###\n",
    "            # as multiply and sum_out methods are finished, in this step we have to call those functions\n",
    "            # so for all the variables, we have to set observed variables to their observed values\n",
    "            # for each other variables let say Z_i, we have to sum out Z_i\n",
    "            # we have to multiply the remaining factors \n",
    "            # finally we have to normalize by dividing the result factor \n",
    "            pass\n",
    "            ### your code ends here ###\n",
    "\n",
    "        current_factor = self.__multiply_factors\n",
    "        (factors, current_factor, dependency_levels, -1)\n",
    "        alpha = sum(np.array(current_factor.probabilities))\n",
    "\n",
    "        distribution = dict()\n",
    "        for i,value in enumerate(current_factor.values):\n",
    "            distribution[value[0]] = current_factor.probabilities[i] / alpha\n",
    "\n",
    "        return distribution\n",
    "\n",
    "    def __find_dependency_levels(self, known_variables, hidden_variables):\n",
    "        '''Looks for the level at which a term can be\n",
    "        extracted in front of an inner summation.\n",
    "        Doing this for each of the variables allows us to\n",
    "        decompose the summation over the hidden variables appropriately.\n",
    "\n",
    "        Keyword arguments:\n",
    "        known_variables -- A list containing evidence variables\n",
    "                           and the query variable.\n",
    "        hidden_variables -- A list of hidden variables.\n",
    "\n",
    "        Returns:\n",
    "        variables -- A 'numpy.array' of variables in the network.\n",
    "        dependency_levels -- A 'numpy.array' containing zero-based indices\n",
    "                             that indicate the level at which we can extract\n",
    "                             a certain term in front of an inner summation.\n",
    "                             The indices of this array and the array 'variables'\n",
    "                             are aligned, such that 'dependency_level[i]'\n",
    "                             denotes the dependency level of 'variable[i]'.\n",
    "        '''\n",
    "        variables = np.array(self.network.nodes())\n",
    "        dependency_levels = np.zeros(variables.shape, dtype=int)\n",
    "\n",
    "        #we look for dependencies between the CPTs of the known variables\n",
    "        #and the hidden variables and assign an appropriate level to them\n",
    "        for _,variable in enumerate(known_variables):\n",
    "            variable_index = np.where(variables==variable)[0][0]\n",
    "            dependency_levels[variable_index] = -1\n",
    "            for i in range(len(hidden_variables)):\n",
    "                hidden = hidden_variables[i]\n",
    "                children = self.network.successors(hidden)\n",
    "                variable_is_child = len(list(children)) != 0 and variable in children\n",
    "                if variable_is_child:\n",
    "                    dependency_levels[variable_index] = i\n",
    "                    break\n",
    "\n",
    "        #we look for dependencies between the CPTs of the hidden variables\n",
    "        #and the other hidden variables and assign an appropriate level to them\n",
    "        for i,variable in enumerate(hidden_variables):\n",
    "            variable_index = np.where(variables==variable)[0][0]\n",
    "            dependency_levels[variable_index] = i\n",
    "            for j in range(i+1,len(hidden_variables)):\n",
    "                hidden = hidden_variables[j]\n",
    "                children = self.network.successors(hidden)\n",
    "                variable_is_child = len(list(children)) != 0 and variable in children\n",
    "                if variable_is_child:\n",
    "                    dependency_levels[variable_index] = j\n",
    "                    break   \n",
    "\n",
    "        return variables, dependency_levels\n",
    "\n",
    "    def __create_factors(self, evidence_variables, variables, dependency_levels):\n",
    "        '''\n",
    "        Keyword arguments:\n",
    "        evidence_variables -- A dictionary containing evidence variables\n",
    "                              as keys and the observed values as values.\n",
    "        variables -- A list of variables in the network.\n",
    "        dependency_levels -- A 'numpy.array' as returned by\n",
    "                             'self.__find_dependency_levels'.\n",
    "\n",
    "        Returns:\n",
    "        factors -- A list of 'Factor' objects ordered in reverse order\n",
    "                   of the values in 'dependency_levels'.\n",
    "        '''\n",
    "\n",
    "        #we are going to create factors from the highest level of dependency\n",
    "        sorting_indices = np.argsort(dependency_levels)[::-1]\n",
    "        number_of_variables = len(variables)\n",
    "        known_variables = list(evidence_variables.keys())\n",
    "        factors = []\n",
    "        for i in range(number_of_variables):\n",
    "            factor_variables = []\n",
    "            factor_values = []\n",
    "            factor_probabilities = []\n",
    "            variable = variables[sorting_indices[i]]\n",
    "\n",
    "            variable_cardinality = self.network.get_cardinality(variable)\n",
    "            values = np.linspace(0, variable_cardinality, \\\n",
    "                                 variable_cardinality-1, dtype=int)\n",
    "            parents = self.network.get_parents(variable)\n",
    "            if parents == None:\n",
    "                #the factor has an empty scope if we have\n",
    "                #an evidence variable that doesn't have any parents\n",
    "                if variable in known_variables:\n",
    "                    evidence_value = evidence_variables[variable]\n",
    "                    value_index = np.where(values == evidence_value)[0]\n",
    "                    cpt = self.network.get_cpds(variable)\n",
    "                    factor_values.append(values[value_index])\n",
    "                    factor_probabilities.append(cpt.get_values()[value_index])\n",
    "                else:\n",
    "                    cpt = self.network.get_cpds(variable)\n",
    "                    factor_variables.append(variable)\n",
    "                    for i,val in enumerate(values):\n",
    "                        factor_values.append([val])\n",
    "                        factor_probabilities.append(cpt.get_values()[i])\n",
    "            else:\n",
    "                #if the variable is one of the evidence variables,\n",
    "                #the factor will only contain the probabilities\n",
    "                #that correspond to the observed value\n",
    "                if variable in known_variables:\n",
    "                    evidence_value = evidence_variables[variable]\n",
    "                    value_index = np.where(values == evidence_value)[0]\n",
    "                    cpt = self.network.get_cpds(variable)\n",
    "\n",
    "                    #we check if any of the variable's parents\n",
    "                    # is an evidence variable\n",
    "                    known_parents = []\n",
    "                    for _,parent in enumerate(parents):\n",
    "                        if parent in known_variables:\n",
    "                            known_parents.append(parent)\n",
    "\n",
    "                    #if none of the parents are known, we just take \n",
    "                    #the probabilities that correspond to the variable's \n",
    "                    #observed value\n",
    "                    if len(known_parents) == 0:\n",
    "                        factor_variables = list(parents)\n",
    "                        cpt_values = cpt.get_values().flatten()\n",
    "                        for i in range(np.product(cpt.cardinality)):\n",
    "                            parent_assignment = list()\n",
    "                            consistent_assignment = True\n",
    "                            for var, value in cpt.assignment([i])[0]:\n",
    "                                if var == variable and value != evidence_value:\n",
    "                                    consistent_assignment = False\n",
    "                                    break\n",
    "                                elif var != variable:\n",
    "                                    parent_assignment.append(value)\n",
    "\n",
    "                            if consistent_assignment:\n",
    "                                factor_values.append(parent_assignment)\n",
    "                                factor_probabilities.append(cpt_values[i])\n",
    "                    #if some of the parents are also evidence variables,\n",
    "                    #we take the probabilities that correspond\n",
    "                    #to the observed values\n",
    "                    else:\n",
    "                        factor_variables = list(set(parents) - set(known_parents))\n",
    "                        parent_indices = [x for x,val in enumerate(parents)\\\n",
    "                                          if val in known_parents]\n",
    "                        for i in range(np.product(cpt.cardinality)):\n",
    "                            parent_assignment = list()\n",
    "                            consistent_assignment = True\n",
    "                            for var, value in cpt.assignment([i])[0]:\n",
    "                                if var == variable and value != evidence_value:\n",
    "                                    consistent_assignment = False\n",
    "                                    break\n",
    "                                elif var != variable:\n",
    "                                    if value == evidence_variables[var]:\n",
    "                                        parent_assignment.append(value)\n",
    "                                    else:\n",
    "                                        consistent_assignment = False\n",
    "                                        break\n",
    "\n",
    "                            if consistent_assignment:\n",
    "                                factor_values.append(parent_assignment)\n",
    "                                factor_probabilities.append(cpt_values[i])\n",
    "                else:\n",
    "                    cpt = self.network.get_cpds(variable)\n",
    "\n",
    "                    #we check if any of the variable's parents\n",
    "                    #is an evidence variable\n",
    "                    known_parents = []\n",
    "                    for _,parent in enumerate(parents):\n",
    "                        if parent in known_variables:\n",
    "                            known_parents.append(parent)\n",
    "\n",
    "                    if len(known_parents) == 0:\n",
    "                        factor_variables = list(parents)\n",
    "                        factor_variables.insert(0, variable)\n",
    "                        cpt_values = cpt.get_values().flatten()\n",
    "\n",
    "                        for i in range(np.product(cpt.cardinality)):\n",
    "                            value_assignment = list()\n",
    "                            for var, value in cpt.assignment([i])[0]:\n",
    "                                value_assignment.append(value)\n",
    "\n",
    "                            factor_values.append(value_assignment)\n",
    "                            factor_probabilities.append(cpt_values[i])\n",
    "                    #if some of the parents are also evidence variables,\n",
    "                    #we take the probabilities that correspond\n",
    "                    #to the observed values\n",
    "                    else:\n",
    "                        factor_variables = list(set(parents) - set(known_parents))\n",
    "                        parent_indices = [x for x,val in enumerate(parents) \\\n",
    "                                          if val in known_parents]\n",
    "                        cpt_values = cpt.get_values().flatten()\n",
    "\n",
    "                        for i in range(np.product(cpt.cardinality)):\n",
    "                            value_assignment = list()\n",
    "                            consistent_assignment = False\n",
    "                            for var, value in cpt.assignment([i])[0]:\n",
    "                                if var == variable:\n",
    "                                    value_assignment.append(value)\n",
    "                                else:\n",
    "                                    if value == evidence_variables[var]:\n",
    "                                        value_assignment.append(value)\n",
    "                                    else:\n",
    "                                        consistent_assignment = False\n",
    "                                        break\n",
    "\n",
    "                            if consistent_assignment:\n",
    "                                factor_values.append(value_assignment)\n",
    "                                factor_probabilities.append(cpt_values[i])\n",
    "                        factor_variables.insert(0, variable)\n",
    "            new_factor = Factor(factor_variables, factor_values, factor_probabilities)\n",
    "            factors.append(new_factor)\n",
    "        return factors\n",
    "\n",
    "    def __multiply_factors(self, factors, current_factor, \\\n",
    "                           dependency_levels, current_dependency_level):\n",
    "        '''Multiplies the factors that are at the\n",
    "        distribution summation's current level.\n",
    "\n",
    "        Keyword arguments:\n",
    "        factors -- A list of factors.\n",
    "        current_factor -- A factor storing partially computed values;\n",
    "                          if its list of variables is empty, we are\n",
    "                          just starting the computations in the network.\n",
    "        dependency_levels -- A 'numpy.array' as returned by\n",
    "                             'self.__find_dependency_levels'.\n",
    "        current_dependency_level -- The distribution summation's current level.\n",
    "\n",
    "        Returns:\n",
    "        current_factor -- A factor storing partially computed updated values.\n",
    "        '''\n",
    "        number_of_factors_to_multiply = \\\n",
    "        len(np.where(dependency_levels==current_dependency_level)[0])\n",
    "        if number_of_factors_to_multiply == 1:\n",
    "            if len(current_factor.probabilities) == 0:\n",
    "                current_factor = factors[0]\n",
    "            else:\n",
    "                current_factor = current_factor.multiply(factors[0])\n",
    "            factors.pop(0)\n",
    "        else:\n",
    "            for i in range(number_of_factors_to_multiply):\n",
    "                if len(current_factor.probabilities) == 0:\n",
    "                    current_factor = factors[0]\n",
    "                else:\n",
    "                    current_factor = current_factor.multiply(factors[0])\n",
    "                factors.pop(0)\n",
    "        return current_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Markov chain Monte Carlo (MCMC)  sampling [60 points]\n",
    "\n",
    "Your second task for today is that of implementing Gibbs sampling for performing approximate inference in a Bayesian network.\n",
    "Gibbs-sampling is the form of MCMC which Prof. Prassler used during the lecture today. You can refer to the example at slide 74.\n",
    "\n",
    "We are now working with only one class, called *ApproximateInferenceEngine*, which exposes one method, i.e *perform_inference*; compared to the exact inference version, this method takes an additional parameter, namely the number of samples that we want to generate. The class also has two private methods, namely *\\_\\_generate_gibbs_sample* and *\\_\\_get_parent_assignment_idx*. *\\_\\_generate_gibbs_sample* does exactly what the name suggests, i.e. it uses Gibbs sampling for generating a sample from the distribution. *\\_\\_get_parent_assignment_idx* is an implementation-specific function, on the other hand; we are using *pgmpy* for storing the network and its CPTs and given that *pgmpy* doesn't have a function that returns the conditional probability of a variable for a given assignment to the parent variables, we have implemented this ourselves.\n",
    "\n",
    "**Your task in this exercise is to implement quite a lot of the functionality of *\\_\\_generate_gibbs_sample* and the main inference loop in *perform_inference* (which amounts to you calling the appropriate methods with the appropriate parameters)**. Just as above, the code contains quite a lot of comments, so you should in principle be able to figure out what you're supposed to do.\n",
    "\n",
    "*Hint*: While implementing *\\_\\_generate_gibbs_sample*, you will have to access the values of the variables and their CPTs, so you should familiarise yourself both with how *pgmpy* stores these and with the meaning of *pgmpy*'s exposed methods. *\\_\\_get_parent_assignment_idx* does some of the work for you, but you still have to do a few things on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproximateInferenceEngine(object):\n",
    "    def __init__(self, network):\n",
    "        self.network = network\n",
    "\n",
    "    def perform_inference(self, query_variable, evidence_variables, \\\n",
    "                          number_of_samples):\n",
    "        '''Calculates the probability distribution\n",
    "        P(query_variable|evidence_variables) using\n",
    "        Gibbs sampling. Assumes that we have only one query variable.\n",
    "\n",
    "        Keyword arguments:\n",
    "        query_variable -- The name of the query variable.\n",
    "        evidence_variables -- A dictionary containing variable names\n",
    "                              as keys and observed values as values.\n",
    "        number_of_samples -- The number of samples that should be used\n",
    "                             in the sampling process.\n",
    "\n",
    "        Returns:\n",
    "        distribution -- A dictionary containing the values of the\n",
    "                        query variable as keys and the probabilities as values.\n",
    "        '''\n",
    "        query_cpt = self.network.get_cpds(query_variable)\n",
    "        number_of_variable_values = query_cpt.cardinality[0]\n",
    "\n",
    "        distribution = dict()\n",
    "        for i in range(number_of_variable_values):\n",
    "            distribution[i] = 0.\n",
    "\n",
    "        variable_assignments = dict()\n",
    "\n",
    "        #we initialise the variables randomly before generating samples\n",
    "        for _,variable in enumerate(self.network.nodes()):\n",
    "            if variable in evidence_variables.keys():\n",
    "                variable_assignments[variable] = evidence_variables[variable]\n",
    "            else:\n",
    "                value = np.random.randint(0, network.get_cardinality(variable))\n",
    "                variable_assignments[variable] = value\n",
    "\n",
    "        for i in range(number_of_samples):\n",
    "            ### write your code here ###\n",
    "\n",
    "            # we need to pick a non-evidence variable X_i randomly \n",
    "            # and we need to sample it from P(X_i, x_1, ..., x_i-1, x+1, x_n)\n",
    "            # then we need to keep all other values \n",
    "            # finally get get new sample\n",
    "            # we have to repeat these steps as much as we want\n",
    "\n",
    "            pass\n",
    "            ### your code ends here\n",
    "\n",
    "        normaliser = 0.\n",
    "        for key in distribution.keys():\n",
    "            normaliser = normaliser + distribution[key]\n",
    "\n",
    "        if normaliser > 1e-10:\n",
    "            for key in distribution.keys():\n",
    "                distribution[key] = distribution[key] / normaliser\n",
    "        return distribution\n",
    "\n",
    "    def __generate_gibbs_sample(self, variable_assignments, evidence_variables):\n",
    "        '''Generates a random assignment for the\n",
    "        non-evidence variables in the network, sampling\n",
    "        each of them given their Markov blanket.\n",
    "\n",
    "        Keyword arguments:\n",
    "        variable_assignments -- A dictionary containing variable names\n",
    "                                as keys and variable assignments as values.\n",
    "        evidence_variables -- A dictionary containing variable names\n",
    "                              as keys and observed values as values.\n",
    "\n",
    "        Returns:\n",
    "        variable_assignments -- A dictionary containing variable names\n",
    "                                as keys and variable assignments as values.\n",
    "        '''\n",
    "        variables_to_sample = list(set(self.network.nodes()) - \\\n",
    "                                   set(evidence_variables.keys()))\n",
    "\n",
    "        # as we have set evidence variables to the observed values \n",
    "        # we need to set all other variables to random variables\n",
    "        for variable in variables_to_sample:\n",
    "            value_probabilities = dict()\n",
    "            cpt = self.network.get_cpds(variable).get_values().flatten()\n",
    "            number_of_values = self.network.get_cardinality(variable)\n",
    "            for value in range(number_of_values):\n",
    "                value_probabilities[value] = 1.\n",
    "\n",
    "            #we calculate the product of the probabilities of the children\n",
    "            #given their parents if the variable has any children\n",
    "            if len(self.network.successors(variable)) != 0:\n",
    "                ### write your code here ###\n",
    "                # in this case we check if it has any children or not\n",
    "                # if it has children we multiply the probabiliites of the children \n",
    "                # by P(X) = P(X | Parents(X))\n",
    "                pass\n",
    "                ### your code ends here ###\n",
    "\n",
    "            normaliser = 0.\n",
    "\n",
    "            #we multiply the children probability by the \n",
    "            #probability of the current variable given its parents\n",
    "            #(or by its prior if it has no parents)\n",
    "            if len(self.network.get_parents(variable)) == 0:\n",
    "                ### write your code here ###\n",
    "                # in bayes network, we know that variable is conditionally independent of all others given its Markov blanket\n",
    "                # so we may write it as P(X_i, MB(X_i))\n",
    "                # so we need to sample from it\n",
    "                pass\n",
    "                ### your code ends here ###\n",
    "            else:\n",
    "                ### write your code here ###\n",
    "                # else returns if it does not have any parents\n",
    "                # so in this case we will multiply by their prior \n",
    "                pass\n",
    "                ### your code ends here ###\n",
    "\n",
    "            for _,key in enumerate(value_probabilities.keys()):\n",
    "                value_probabilities[key] = value_probabilities[key] / normaliser\n",
    "\n",
    "            # we now generate a value for the variable\n",
    "            # by sampling from its distribution\n",
    "\n",
    "            value = -1 \n",
    "            ### write your code here ###\n",
    "\n",
    "            # as \n",
    "\n",
    "            ### your code ends here ###\n",
    "            variable_assignments[variable] = value\n",
    "\n",
    "        return variable_assignments\n",
    "\n",
    "    def __get_parent_assignment_idx(self, variable, assigned_values):\n",
    "        '''Returns the assigned values to the parent variables of a given variable.\n",
    "\n",
    "        Keyword arguments:\n",
    "        variable -- A string representing a variable in the network.\n",
    "        assigned_values -- A dictionary containing value assignments to variables.\n",
    "\n",
    "        Returns:\n",
    "        parent_value_idx -- An integer representing the CPT value index\n",
    "                            corresponding to the assigned parent values.\n",
    "        '''\n",
    "        if len(self.network.get_parents(variable)) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            parent_value_idx = -1\n",
    "            cpt = self.network.get_cpds(variable)\n",
    "            for i in range(np.product(cpt.cardinality)):\n",
    "                consistent_assignment = True\n",
    "                for var, value in cpt.assignment([i])[0]:\n",
    "                    if value != assigned_values[var]:\n",
    "                        consistent_assignment = False\n",
    "                        break\n",
    "                if consistent_assignment:\n",
    "                    parent_value_idx = i\n",
    "                    break\n",
    "            return parent_value_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing your code\n",
    "\n",
    "We'll test our inference engines using the alarm network from the textbook. The code that creates the network and calls the inference functions for answering two queries - $P(Burglary | JohnCalls = 1, MaryCalls = 1)$ and $P(JohnCalls | MaryCalls = 1)$ - is already implemented in the cell below. What you have to do is thus run this cell after completing the implementation of variable elimination and Gibbs sampling, verifying that the results you obtain are the expected ones:\n",
    "\n",
    "* $P(Burglary | JohnCalls = 1, MaryCalls = 1) \\approx < 0.72, 0.28>$\n",
    "* $P(JohnCalls | MaryCalls = 1) \\approx < 0.82, 0.18>$\n",
    "\n",
    "*Note*: The sampling code is likely to be a bit slow, so wait for a few seconds after you run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/probabilistic-reasoning/lib/python3.9/site-packages/pgmpy/models/BayesianModel.py:8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Please use BayesianNewtork class, BayesianModel will be removed in future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'probabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sq/cnmw1cts0hn9_9__lb3yxclm0000gn/T/ipykernel_11524/1371473744.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mevidence_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'JohnCalls'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MaryCalls'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mresulting_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexact_inference_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_inference\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exact: P(Burglary | JohnCalls, MaryCalls) ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresulting_distribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sq/cnmw1cts0hn9_9__lb3yxclm0000gn/T/ipykernel_11524/1875470528.py\u001b[0m in \u001b[0;36mperform_inference\u001b[0;34m(self, query_variable, evidence_variables)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mcurrent_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__multiply_factors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency_levels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_factor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'probabilities'"
     ]
    }
   ],
   "source": [
    "# creating a test Bayesian network\n",
    "network = BayesianModel([('Burglary', 'Alarm'), \\\n",
    "                        ('Earthquake', 'Alarm'), \\\n",
    "                        ('Alarm', 'JohnCalls'), \\\n",
    "                        ('Alarm', 'MaryCalls')])\n",
    "\n",
    "# creating the CPTs of the test Bayesian network\n",
    "cpd_burglary = TabularCPD(variable='Burglary', variable_card=2, \\\n",
    "                          values=[[0.999], [0.001]])\n",
    "cpd_earthquake = TabularCPD(variable='Earthquake', variable_card=2, \\\n",
    "                            values=[[0.998], [0.002]])\n",
    "cpd_alarm = TabularCPD(variable='Alarm', variable_card=2, \\\n",
    "                       values=[[0.999, 0.71, 0.06, 0.05],\n",
    "                               [0.001, 0.29, 0.94, 0.95]], \\\n",
    "                       evidence=['Burglary', 'Earthquake'],\n",
    "                       evidence_card=[2, 2])\n",
    "cpd_john_calls = TabularCPD(variable='JohnCalls', variable_card=2, \\\n",
    "                            values=[[0.95, 0.1], [0.05, 0.9]],\n",
    "                            evidence=['Alarm'], evidence_card=[2])\n",
    "cpd_mary_calls = TabularCPD(variable='MaryCalls', variable_card=2, \\\n",
    "                            values=[[0.99, 0.3], [0.01, 0.7]],\n",
    "                            evidence=['Alarm'], evidence_card=[2])\n",
    "\n",
    "network.add_cpds(cpd_burglary, cpd_earthquake, cpd_alarm, \\\n",
    "                 cpd_john_calls, cpd_mary_calls)\n",
    "network.check_model()\n",
    "\n",
    "exact_inference_engine = ExactInferenceEngine(network)\n",
    "approximate_inference_engine = ApproximateInferenceEngine(network)\n",
    "\n",
    "#print(exact_inference_engine)\n",
    "\n",
    "#############################################\n",
    "# Test 1: P(Burglary | JohnCalls, MaryCalls)\n",
    "#############################################\n",
    "query_variable = 'Burglary'\n",
    "evidence_variables = {'JohnCalls': 1, 'MaryCalls': 1}\n",
    "\n",
    "resulting_distribution = exact_inference_engine.perform_inference\\\n",
    "(query_variable, evidence_variables)\n",
    "print('Exact: P(Burglary | JohnCalls, MaryCalls) =', resulting_distribution)\n",
    "\n",
    "resulting_distribution = approximate_inference_engine.perform_inference\\\n",
    "(query_variable, evidence_variables, 30000)\n",
    "print('Approximate: P(Burglary | JohnCalls, MaryCalls) =', resulting_distribution)\n",
    "\n",
    "###################################\n",
    "# Test 2: P(JohnCalls | MaryCalls)\n",
    "###################################\n",
    "query_variable = 'JohnCalls'\n",
    "evidence_variables = {'MaryCalls': 1}\n",
    "\n",
    "resulting_distribution = exact_inference_engine.perform_inference\\\n",
    "(query_variable, evidence_variables)\n",
    "print('Exact: P(JohnCalls | MaryCalls) =', resulting_distribution)\n",
    "\n",
    "resulting_distribution = approximate_inference_engine.perform_inference\\\n",
    "(query_variable, evidence_variables, 30000)\n",
    "print('Approximate: P(JohnCalls | MaryCalls) =', resulting_distribution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
